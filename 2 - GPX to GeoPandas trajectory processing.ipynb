{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14942a5c",
   "metadata": {},
   "source": [
    "# GPX to Geopandas translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5300e6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from datetime import date\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbd08c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'test.gpx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee55ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the metadata associated with the trajectories in the currently considered GPX.\n",
    "meta_gdf = gpd.read_file(fname, layer = 'tracks')\n",
    "# display(meta_gdf)\n",
    "display(meta_gdf.info())\n",
    "\n",
    "# Read the GPX -- do it in blocks, so that we can also manage huge GPXs.\n",
    "list_gdf = []\n",
    "step = int(2e6)\n",
    "for i in range(0, int(1000e6), step) :\n",
    "    print(f\"Processing points in the range: [{str(i)} -- {str(i + step)})\")\n",
    "\n",
    "    # Read the spatio-temporal information of the trajectories from the current block.\n",
    "    gdf = gpd.read_file(fname, layer = 'track_points', rows = slice(i, i + step))\n",
    "    display(gdf)\n",
    "    display(gdf.info())\n",
    "    \n",
    "    # Early exit: when there are no more rows to read, terminate the loop.\n",
    "    if gdf.shape[0] == 0 :\n",
    "          print(\"No more points to process. Exiting the loop...\")\n",
    "          break\n",
    "    \n",
    "    # Select the columns of interest (trajectory identifier, timestamp, coordinates).\n",
    "    print(\"Filtering useless columns...\")\n",
    "    selection = gdf.loc[:, ['track_fid', 'track_seg_id', 'track_seg_point_id', 'time', \"geometry\"]]\n",
    "    \n",
    "    # Use a compacter representation for 64-bit integer columns.\n",
    "    selection['track_fid'] = selection['track_fid'].astype(np.int32)\n",
    "    selection['track_seg_id'] = selection['track_seg_id'].astype(np.int32)\n",
    "    selection['track_seg_point_id'] = selection['track_seg_point_id'].astype(np.int32)\n",
    "    \n",
    "    selection.info()\n",
    "    \n",
    "    # Drop the rows with missing or nonsensical timestamps.\n",
    "    print(\"Filtering rows with missing or wrong timestamps...\")\n",
    "    selection.dropna(subset=['time'], inplace = True)\n",
    "    selection = selection.loc[(selection['time'] > '1990-01-01') & (selection['time'] <= str(date.today()))]\n",
    "    selection['time'] = pd.to_datetime(selection['time'])\n",
    "    selection.info()\n",
    "\n",
    "    # Associate a true unique identifier with trajectories.\n",
    "    # 'track_fid' represents the identifier of a trajectory within a GPX file. If, however, a trajectory is split across multiple GPXs,\n",
    "    # we cannot use it to reconstruct the trajectory. To solve the problem, we use the information from the 'link' element in a GPX file: \n",
    "    # this is the combination of a user ID AND a ID that OSM associates with a trace.\n",
    "    # This information is available from meta_gdf, so we perform a merge to put it into selection.\n",
    "    print('Merging meta information with the trajectories...')\n",
    "    selection = selection.merge(meta_gdf['link1_href'], left_on = 'track_fid', right_index = True)\n",
    "    selection.rename(columns={'link1_href':'track_uid'}, inplace = True)\n",
    "    selection.info()\n",
    "    \n",
    "    # Append this dataframe to a list.    \n",
    "    list_gdf.append(selection.copy(deep=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a9f362-6c08-4c42-b690-0dde208cbce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e497ea76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the dataframes created previously.\n",
    "final = gpd.GeoDataFrame(pd.concat(list_gdf, ignore_index=True), crs = list_gdf[0].crs)\n",
    "final.info()\n",
    "del list_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7730a8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ogni 'track_fid' puo' contenere al suo interno piu' di una traiettoria (identificata da 'track_seg_id').\n",
    "# Pertanto, genera un ID univoco per ogni traiettoria.\n",
    "final['id'] = final['track_fid'].astype(str) + '_' + final['track_seg_id'].astype(str)\n",
    "final['id'] = final['id'].astype('category')\n",
    "final['id'] = final['id'].cat.codes\n",
    "final.info()\n",
    "print(f\"Numero traiettorie: {final['id'].nunique()}, tmin: {final['time'].min()}, tmax: {final['time'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c47d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva esplicitamente latitudine e longitudine in colonne separate (puo' servire ad alcune librerie, e.g., scikit-mobility)\n",
    "# final['lat'], final['long'] = final['geometry'].y, final['geometry'].x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c3f52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the preprocessed GeoPandas frame to disk.\n",
    "final.to_parquet(fname + '.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
